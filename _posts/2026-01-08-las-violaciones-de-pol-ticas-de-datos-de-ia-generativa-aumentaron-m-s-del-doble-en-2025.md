---
layout: posts
color-schema: red-dark
date: '2026-01-08 08:35 -0400'
published: true
superNews: false
superArticle: false
year: '2026'
title: >-
  Las violaciones de políticas de datos de IA generativa aumentaron más del
  doble en 2025
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/540x320/Trabajo-en-IA-p.jpg
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/1024x680/Trabajo-en-IA-g.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
  - Mexico
tags:
  - Transformación Digital
week: '02'
---
Netskope (NASDAQ: NTSK), líder en seguridad y redes modernas para la era de la nube y la IA, ha publicado la nueva edición de su estudio Cloud and Threat Report (2026), que destaca tanto la rápida proliferación de la IA generativa (GenAI) como la persistencia de la IA en la sombra y las infracciones de las políticas de datos de las empresas analizadas, a pesar de haber adoptado ya herramientas de IA gestionadas y aprobadas por la empresa. El estudio también indica que los esfuerzos por controlar y supervisar el uso de la IA generativa han puesto a prueba la capacidad de los equipos de seguridad para avanzar en la resolución de problemas heredados, como el phishing y la pérdida de datos a través de aplicaciones personales, lo que ha agravado algunos de estos problemas.

- Las violaciones de las políticas de datos asociadas al uso de aplicaciones de IA generativa se han duplicado año tras año, y la empresa media experimenta 223 incidentes al mes.
- Las aplicaciones personales en la nube siguieron siendo una fuente importante de pérdida de datos durante el año, ya que el 60 % de los incidentes de amenazas internas estuvieron relacionados con instancias de aplicaciones personales en la nube en las que se expusieron datos regulados, propiedad intelectual, código fuente y credenciales a niveles preocupantes.
- El phishing siguió representando una parte significativa de los intentos de acceso inicial, con una ligera reducción interanual en los clics de los usuarios.

**El desafío de la GenAI: la aparición de nuevos peligros**

En el último año, las empresas han avanzado significativamente en la implementación de versiones de herramientas genAI aprobadas, como ChatGPT y Gemini. La mayoría de los usuarios del estudio utilizaban estas herramientas aprobadas por la empresa y solo el 47 % seguía utilizando aplicaciones genAI privadas, frente al 78 % de hace un año. Además, el 90 % de las entidades estudiadas han establecido políticas para bloquear activamente una o más aplicaciones de IA generativa potencialmente problemáticas, frente al 80 % de hace un año.

El número total de usuarios de aplicaciones de IA generativa aumentó un 200 % durante el año pasado y el volumen de solicitudes se multiplicó por cinco.

El índice global de violaciones de la política de datos de IA generativa también aumentó año tras año, y las empresas experimentaron una media de 223 incidentes al mes (el doble que el año anterior); el 25 % de las empresas estudiadas sufrieron al menos 2100 incidentes de violación de la política de datos de IA generativa al mes.

**Los viejos problemas siguen estando ahí**

Incluso con un enfoque más actual en los nuevos problemas de seguridad que plantea la IA, los retos de siempre, como el uso de aplicaciones personales de almacenamiento en la nube y el phishing, siguen siendo problemas de seguridad acuciantes.

Las cargas de datos sometidos a controles (como datos personales, financieros o sanitarios) representan la categoría de infracciones de políticas más alta, con un 54 %.

En cuanto al phishing, aunque la incidencia disminuyó en un 27 % interanual, cada mes las organizaciones han visto cómo 87 de cada 10 000 usuarios hacían clic en enlaces sospechosos.

«Los equipos de seguridad de las empresas están en constante cambio y se enfrentan a nuevos retos a medida que las empresas evolucionan y los adversarios innovan», afirma Ray Canzanese, director de Netskope Threat Labs. «Sin embargo, la adopción de la GenAI ha cambiado las reglas del juego. Sobre todo, supone un panorama de amenazas que ha cogido por sorpresa a muchos equipos en cuanto a su alcance y complejidad, hasta el punto de que da la sensación de que se están esforzando por seguir el ritmo y de que pierden de vista algunos aspectos básicos de la seguridad. Los responsables de los equipos de seguridad deben ampliar su estrategia en este ámbito para ser «conscientes de la IA», haciendo evolucionar las políticas y ampliando el alcance de las herramientas existentes, como la DLP, para fomentar el equilibrio entre innovación y seguridad a todos los niveles».

![](https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/540x320/Trabajo-en-IA-p.jpg)

<table style="height: 42px;" width="569">
<tbody>
<tr>
<td style="text-align: justify;"><sub><strong>Nuestras noticias también son publicadas a través de nuestra cuenta en Twitter <a href="https://twitter.com/itnewslat?lang=es">@ITNEWSLAT</a> y en la aplicación <a href="https://squidapp.co/en/">SQUID</a></strong></sub></td>
</tr>
</tbody>
</table>

<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>
