---
layout: posts
color-schema: red-dark
date: '2023-04-27 05:06 -0500'
published: true
superNews: false
superArticle: false
year: '2023'
title: ChatGPT como vehículo para la estafa
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/1024x680/Estafador-digital-g.jpg
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/Estafador-digital-p.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
  - Mexico
tags:
  - Transformación Digital
week: '17'
---
Los dominios recientemente registrados relacionados con ChatGPT han aumentado significativamente, impulsados por ser una de las aplicaciones de más rápido crecimiento en la historia. La contracara de esta popularidad es que ChatGPT también está atrayendo la atención de los estafadores. Las amenazas registran y usan dominios incluyendo las palabras "OpenAI" y "ChatGPT" en su nombre de dominio. Entre noviembre de 2022 y principios de abril de 2023, hubo un aumento del 900 % en los registros mensuales de dominios relacionados con ChatGPT.
 
Cuando OpenAI lanzó su API oficial para ChatGPT el 1 de marzo de 2023, se produjo un número creciente de “servicios” sospechosos que la utilizan, vinculados con potenciales amenazas por el uso de chatbots de imitación. Poco después de que Microsoft anunciara su nueva versión de Bing el 7 de febrero de 2023, se registraron más de 300 dominios falsos relacionados con ChatGPT.
 
Por lo general, los estafadores crean un sitio web fake que imita la estética del sitio web oficial de ChatGPT y luego engañan a los usuarios para que descarguen malware o compartan información confidencial.
 
Una técnica común que usan los estafadores para entregar malware, presenta a los usuarios un botón "DESCARGAR PARA WINDOWS" que, una vez que se hace click, descarga el malware troyano en sus dispositivos sin que las víctimas se den cuenta del riesgo.
 
Los estafadores también están recurriendo a la ingeniería social relacionada con ChatGPT para el robo de identidad o el fraude financiero. A pesar de que OpenAI brinda a los usuarios una versión gratuita de ChatGPT, los estafadores conducen a las víctimas a sitios web fraudulentos, alegando que deben pagar por estos servicios.  Intentando convencer a las víctimas para que proporcionen su información confidencial, como los detalles de la tarjeta de crédito y la dirección de correo electrónico.
 
Otros utilizan a OpenAI para ejecutar criptofraudes usando el logo de OpenAI y el nombre de Elon Musk para promocionar y capturar la atención de las víctimas a este evento fraudulento de sorteo de criptomonedas.
 
Los usuarios de ChatGPT deben prestar especial atención con los correos electrónicos o enlaces sospechosos relacionados con ChatGPT. Además, el uso de chatbots de imitación aumenta el riesgo de exposición. Los usuarios siempre deben acceder a ChatGPT a través del sitio web oficial de OpenAI.
 
Durante 2022 las campañas de phishing aumentaron casi un 50 %, paradójicamente impulsadas por nuevas herramientas de inteligencia artificial y kits de phishing accesibles para los ciberdelincuentes, este 2023 tiene como protagonista y anzuelo a OpenAI y ChatGPT. Los ciberdelincuentes refinan continuamente sus métodos para hacerlos más sofisticados y difíciles de identificar o prevenir.

![](https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/Estafador-digital-p.jpg)

<table style="height: 42px;" width="569">
<tbody>
<tr>
<td style="text-align: justify;"><sub><strong>Nuestras noticias también son publicadas a través de nuestra cuenta en Twitter <a href="https://twitter.com/itnewslat?lang=es">@ITNEWSLAT</a> y en la aplicación <a href="https://squidapp.co/en/">SQUID</a></strong></sub></td>
</tr>
</tbody>
</table>
<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>