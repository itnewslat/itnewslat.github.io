---
layout: posts
color-schema: red-dark
date: '2026-01-10 20:09 -0400'
published: true
superNews: false
superArticle: false
year: '2026'
title: >-
  Desnudez digital: el uso malicioso de la IA acelera la creación de imágenes
  sin consentimiento
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/540x320/Grok-p.jpg
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/1024x680/Grok-g.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
  - Mexico
tags:
  - Seguridad
week: '02'
---
**ESET analiza el caso de Grok en X y advierte sobre los riesgos de la generación de imágenes íntimas sin consentimiento y el avance de la violencia digital en México.**

El uso indebido de herramientas de Inteligencia Artificial (IA) para la creación y manipulación de imágenes se ha consolidado como una nueva amenaza digital que impacta directamente la privacidad, la reputación y la seguridad de las personas. En particular, la generación de imágenes íntimas o sexualizadas sin consentimiento, conocida como desnudez digital, ha encendido alertas a nivel internacional por su rápida expansión. ESET, compañía líder en detección proactiva de amenazas, analiza este fenómeno y su avance, así como el panorama de esta situación en México.

A nivel global, uno de los casos recientes de este problema es Grok, la IA desarrollada por xAI e integrada a la red social X. A diferencia de otros modelos de IA que operan como servicios independientes, Grok funciona dentro de una red social masiva, lo que le permite acceder de forma inmediata a imágenes públicas y responder en tiempo real a solicitudes de los usuarios.

Un análisis independiente realizado por Genevieve Oh, reveló que durante un periodo de 24 horas la cuenta oficial de @Grok generó aproximadamente 6,700 imágenes por hora clasificadas como sexualmente sugerentes o “nudificadas” a principios de enero. Esta cifra resulta alarmante al compararla con el promedio de las imágenes generadas por los cinco principales sitios dedicados a deepfakes sexuales que produjeron alrededor de 79 imágenes por hora.

Durante el periodo crítico, los filtros de seguridad y moderación resultaron insuficientes, lo que permitió que los usuarios pudieran hacer solicitudes para cambiar vestimenta, alterar cuerpos o generar versiones sexualizadas de persones reales, sin ser bloqueados de forma efectiva.

“La combinación de IA generativa y plataformas masivas, acelera la creación de este tipo de contenido a una escala nuca antes vista. Lo preocupante es que el daño para las víctimas ocurre en minutos, mientras las consecuencias legales y emocionales pueden durar años”, asegura David González, investigador de seguridad informática de ESET.

Aunque el caso de Grok es el más reciente, México ya había registrado incidentes graves de uso de IA desde 2023, como el caso de un exalumno del Instituto Politécnico Nacional (IPN), acusado de manipular imágenes de compañeras mediante IA para crear y distribuir contenido sexual sin consentimiento, de acuerdo con la investigación, se encontraron más de 160,000 fotografías y alrededor de 20,000 videos alterados digitalmente.

“Este caso dejó en evidencia que el potencial de estas tecnologías para facilitar la violencia digital a gran escala y hacerlos difíciles de contener”, comenta el investigador de ESET.

En México, la Ley Olimpia constituye un pilar legal fundamental al sancionar la difusión de contenido íntimo sin consentimiento, incluyendo material manipulado o generado digitalmente. Sin embargo, el crecimiento de los casos vinculados a IA requiere medidas mayores.

Entre 2024 y 2025 entidades como el Estado de México, Sinaloa, Aguascalientes, San Luis Potosí y Colima reformaron sus códigos penales para aprobar sanciones que incluyen penas de prisión y multas ante delitos de violencia digital.

“Muchas personas aún desconocen que crear o compartir una imagen íntima generada con IA puede ser un delito, incluso si nunca existió una fotografía original”, agrega González.

Ante este escenario, desde ESET recomiendan:

- No utilizar herramientas de IA para crear o modificar imágenes de personas reales sin su consentimiento.
- Proteger la privacidad y limitar la exposición de fotografías personales en redes sociales.
- Verificar el origen de imágenes virales o altamente realistas antes de compartirlas.
- Denunciar contenido íntimo no consensuado en plataformas digitales y ante autoridades.
- Promover la educación digital para comprender los riesgos legales y éticos de la IA.

“La Inteligencia Artificial es una herramienta poderosa, pero como cualquier tecnología, su impacto depende de cómo se utilice. Sin límites claros y sin una cultura responsable, puede convertirse en una herramienta de abuso”, concluye el experto de ESET.

Para saber más sobre seguridad informática visite el portal corporativo de ESET: https://www.welivesecurity.com/es/

Por otro lado, ESET invita a conocer Conexión Segura, su podcast para saber qué está ocurriendo en el mundo de la seguridad informática. Para escucharlo ingrese a: https://open.spotify.com/show/0Q32tisjNy7eCYwUNHphcw


![](https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/540x320/Grok-p.jpg)

<table style="height: 42px;" width="569">
<tbody>
<tr>
<td style="text-align: justify;"><sub><strong>Nuestras noticias también son publicadas a través de nuestra cuenta en Twitter <a href="https://twitter.com/itnewslat?lang=es">@ITNEWSLAT</a> y en la aplicación <a href="https://squidapp.co/en/">SQUID</a></strong></sub></td>
</tr>
</tbody>
</table>

<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>