---
layout: posts
color-schema: red-dark
date: '2025-03-12 03:21 -0400'
published: true
superNews: false
superArticle: false
year: '2025'
title: Crecen las estafas que utilizan clonación de voz con Inteligencia Artificial
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/540x320/Voz-p.jpg
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/1024x680/Voz-g.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
  - Mexico
tags:
  - Seguridad
week: '12'
---
**Este engaño no solo está en pleno aumento, sino que es cada vez más realista gracias a la IA, es por eso que ESET advierte cómo reconocerlos y qué medidas tomar para no ser víctima.**

No es una novedad que la Inteligencia Artificial llegó para revolucionar el mundo, y los ciberdelincuentes han sabido aprovechar todo este potencial para armar ataques de ingeniería social dirigidos, más realistas y sofisticados. Las técnicas que involucran la clonación de voz para hacerse pasar por familiares, amigos o conocidos están en pleno auge con el objetivo obtener información privada o directamente dinero de sus víctimas. ESET, compañía líder en detección proactiva de amenazas, analiza la metodología que utilizan los atacantes en este tipo de engaños, cómo pueden afectar a las personas y de qué manera evitar ser víctima.
 
Los cibercriminales toman pequeños fragmentos de una grabación real y mediante el uso de la Inteligencia Artificial y los patrones de voz, crean conversaciones y frases para llevar a cabo sus engaños, con consecuencias tan graves como costosas.  Estas muestras las obtienen de grabaciones de voz o de videos que estén publicados en redes sociales como Instagram o TikTok.
 
Para dimensionar cuál es su impacto, la Comisión Federal de Comercio de los Estados Unidos informó que solo en 2023 ese país perdió 2.700 millones de dólares solo por estafas. En esa línea, Starling Bank (banco británico que opera de manera online) alertó sobre la preponderancia de este tipo de estafas en el Reino Unido. La encuesta realizada a más de 3.000 personas reveló que más de una cuarta parte de los adultos afirma haber sido víctima de una estafa de clonación de voz mediante inteligencia artificial al menos una vez en el año. Además, el 46% de los encuestados mencionó que no sabía que existían tales estafas.
 
El crecimiento del número de estafas que involucran a la Inteligencia Artificial llevó al FBI a emitir un comunicado para alertar a las personas: “Los atacantes están aprovechando la IA para crear mensajes de voz o video y correos electrónicos muy convincentes para permitir esquemas de fraude contra individuos y empresas por igual. Estas tácticas sofisticadas pueden resultar en pérdidas financieras devastadoras, daño a la reputación y compromiso de datos confidenciales”, remarcaron desde el organismo.
 
Desde ESET advierten que ante este tipo de estafas que involucran la ingeniería social, el primer consejo es mantenerse bien alerta. Esto quiere decir, prestar especial atención a aquellos mensajes inesperados que llegan con la urgencia de solicitar dinero o credenciales de ciertas cuentas. Y en esa misma línea, devolver la llamada al familiar o amigo en cuestión a un número de teléfono conocido.
 
Otra de las medidas sugeridas por el equipo de investigación de ESET es tener una “frase segura”, que sea acordada previamente entre familiares y amigos, con el objetivo de comprobar si la persona que está hablando del otro lado es quien realmente dice ser.
 
También es muy importante implementar la autenticación multifactor siempre que se pueda. Se trata de agregar una capa de seguridad extra, con el objetivo de que los ciberdelincuentes no puedan acceder a nuestras cuentas y sistemas.
 
“En el caso de las empresas, más allá de combinar soluciones para reducir la cantidad de correos electrónicos, llamadas y mensajes de phishing que llegan a sus colaboradores, es primordial que puedan educar y concientizar a sus equipos de colaboradores para que puedan detectar los engaños y no caer en la trampa.”, comenta Camilo Gutiérrez Amaya, Jefe del Laboratorio de investigación de ESET Latinoamérica.
 
Para saber más sobre seguridad informática visite el portal de noticias de ESET: https://www.welivesecurity.com/es/estafas-enganos/clonacion-voz-inteligencia-artificial-ia/

Por otro lado, ESET invita a conocer Conexión Segura, su podcast para saber qué está ocurriendo en el mundo de la seguridad informática. Para escucharlo ingrese a: https://open.spotify.com/show/0Q32tisjNy7eCYwUNHphcw

![](https://raw.githubusercontent.com/itnewslat/assets/refs/heads/master/img/540x320/Voz-p.jpg)

<table style="height: 42px;" width="569">
<tbody>
<tr>
<td style="text-align: justify;"><sub><strong>Nuestras noticias también son publicadas a través de nuestra cuenta en Twitter <a href="https://twitter.com/itnewslat?lang=es">@ITNEWSLAT</a> y en la aplicación <a href="https://squidapp.co/en/">SQUID</a></strong></sub></td>
</tr>
</tbody>
</table>

<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>