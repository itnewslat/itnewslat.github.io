---
layout: posts
color-schema: red-dark
date: '2024-03-13 17:02 -0400'
published: true
superNews: false
superArticle: false
year: '2024'
title: "¿Es seguro ChatGPT? Medidas destinadas para protegerse\_"
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/CHATGPT-P.jpg
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/1024x680/CHATGPT-G.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
  - Mexico
tags:
  - Seguridad
week: '11'
---
A medida que se generaliza el uso de la IA generativa y otras herramientas innovadoras como ChatGPT, es fundamental comprender qué tan seguras son.  Desde Avast se exploran consejos de seguridad sobre ChatGPT, las estafas de ChatGPT y otras amenazas a tener en cuenta. 

Si bien existen preocupaciones sobre la privacidad de ChatGPT y ejemplos de estafas de malware de ChatGPT, el chatbot que cambia las reglas del juego tiene muchas barreras de seguridad incorporadas y generalmente se considera seguro de usar. Sin embargo, al igual que con cualquier herramienta en línea, especialmente las nuevas, es importante practicar una buena higiene digital y mantenerse informado sobre las posibles amenazas a la privacidad, así como sobre las formas en que la herramienta puede ser mal utilizada. 

Con su capacidad para escribir contenido similar al humano, ChatGPT se ha vuelto rápidamente popular entre estudiantes, profesionales y usuarios ocasionales. Pero con todo el bombo que lo rodea, y las primeras historias sobre la tendencia de GPT a alucinar, las preocupaciones sobre la seguridad de ChatGPT están justificadas. 

Por eso, Avast, marca líder en ciberseguridad y parte de Gen™, describe las cosas clave que se necesitan saber sobre la seguridad de ChatGPT,  explora sobre los riesgos de seguridad que pueden existir y ofrece algunos consejos para usar ChatGPT de manera segura. 

**Estafas de ChatGPT y riesgos a evitar** 

Si bien OpenAI garantiza que ChatGPT se construya con muchas medidas de seguridad no está exento de riesgos. Estas son algunas de los posibles riesgos y estafas de seguridad de ChatGPT: 

**Filtraciones de datos**: Una violación de datos se produce cuando se exponen datos confidenciales o privados sin autorización, a los que se podría acceder y utilizar para beneficiar a un ciberdelincuente. Por ejemplo, si los datos personales que se compartieron en una conversación con ChatGPT se ven comprometidos, se está en riesgo de robo de identidad.  

**Phishing**: El phishing es un conjunto de tácticas de manipulación que los ciberdelincuentes utilizan para engañar a las personas para que proporcionen información confidencial, como contraseñas o detalles de tarjetas de crédito. Ciertos tipos de phishing, como el phishing por correo electrónico o el phishing de clones, involucran a estafadores que se hacen pasar por una fuente confiable, como su banco o empleador.  

Uno de los puntos débiles de las tácticas de phishing es la presencia de signos reveladores, como la mala ortografía o la gramática. Pero ChatGPT ahora puede ser utilizado por los estafadores para crear correos electrónicos de phishing altamente realistas, en muchos idiomas, que pueden engañar fácilmente a las personas. 

**Desarrollo de malware**: El malware es un software malicioso que los ciberdelincuentes utilizan para obtener acceso y dañar un sistema informático o una red. Todos los tipos de malware requieren código informático, lo que significa que los piratas informáticos generalmente tienen que conocer un lenguaje de programación para crear malware nuevo.  

Los estafadores ahora pueden usar ChatGPT para escribir o al menos "mejorar" el código de malware para ellos. Aunque ChatGPT cuenta con medidas de seguridad para evitar que sucedan tales cosas, ha habido casos de usuarios que lograron eludir esas restricciones. 

**Catfishing**: El catfishing es una práctica engañosa que consiste en crear una identidad falsa en línea para engañar a otros con fines maliciosos, como estafas o robo de identidad. Como la mayoría de las tácticas de ingeniería social, el catfishing requiere excelentes habilidades de suplantación de identidad. Pero los piratas informáticos podrían usar ChatGPT para crear conversaciones más realistas o incluso para hacerse pasar por personas específicas.  

**Desinformación**: La fortaleza de ChatGPT es su capacidad para imitar la forma en que los humanos escriben y usan el lenguaje. Si bien el modelo de lenguaje se  nutre de grandes cantidades de datos y puede responder muchas preguntas complejas con precisión se sabe que comete errores graves y genera contenido falso, un fenómeno llamado "alucinación". Siempre que se utilice ChatGPT o cualquier otra IA generativa, es crucial comprobar la información que produce, ya que a menudo puede inventar cosas y ser muy convincente. 

**Whaling**: Este es un ataque cibernético que se dirige a una persona de alto perfil, como un ejecutivo de negocios o un alto funcionario dentro de una organización, generalmente con el objetivo de robar información confidencial o cometer fraude financiero. Si bien las empresas pueden protegerse de muchos ataques mediante el uso de las mejores prácticas de ciberseguridad, un hacker podría utilizar ChatGPT para crear correos electrónicos realistas que puedan eludir los filtros de seguridad y utilizarse en un ataque de whaling. 

**Consejos para protegerse mientras usas ChatGPT**

A pesar de las medidas de seguridad de ChatGPT, como con cualquier herramienta en línea, existen riesgos. Estos son algunos consejos de seguridad clave y las mejores prácticas para mantenerse seguro mientras usa ChatGPT: 

1. **Evitar compartir información confidencial**. Es importante mantener la privacidad de los datos personales y nunca revelar información financiera u otra información confidencial durante las conversaciones con ChatGPT. 

2. **Revisar las políticas de privacidad**. Se recomienda leer la política de privacidad de OpenAI para comprender cómo se manejan los datos y qué nivel de control se tiene sobre ellos. 

3. **Usar una cuenta anónima**. Considerar usar una cuenta anónima para interactuar con ChatGPT teniendo una barrera adicional de privacidad digital. Aunque es posible que se deba proporcionar y verificar un número de teléfono para registrarse.   

4. **Utilizar una contraseña segura**. Seguir las buenas prácticas de seguridad creando contraseñas diferentes, seguras y únicas, siendo fundamental cambiarlas periódicamente para mantener su cuenta segura.  

5. **Mantenerse informado**. Estar actualizado sobre los últimos problemas de seguridad de inteligencia artificial y estafas en línea relacionadas. El conocimiento es poder cuando se trata de ciberseguridad. 

6. **Utilizar un software antivirus**. Un buen software antivirus como Avast puede ayudar a proteger los dispositivos de posibles amenazas cibernéticas al estar basado en una potente tecnología antimalware heurística para ayudar a protegerse contra las amenazas de malware nuevas y emergentes. Además, cuenta con una VPN incorporada para cifrar la información que se envían y se reciben en línea ayudando a proteger los datos personales.  

Javier Rincón, Director Regional Latam de Avast, menciona “Un paso importante para protegerse de la exposición de datos confidenciales es ser consciente de cómo un sitio web, una aplicación o un chatbot utiliza los datos personales. Para ello, hay que fortalecerse y protegerse de la constante evolución de la vida digital para poder  poder mitigar los posibles riesgos asociados con las estafas de chatbots, como las violaciones de datos o los ataques de malware”. 

 ![](https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/CHATGPT-P.jpg)
 
 <table style="height: 42px;" width="569">
<tbody>
<tr>
<td style="text-align: justify;"><sub><strong>Nuestras noticias también son publicadas a través de nuestra cuenta en Twitter <a href="https://twitter.com/itnewslat?lang=es">@ITNEWSLAT</a> y en la aplicación <a href="https://squidapp.co/en/">SQUID</a></strong></sub></td>
</tr>
</tbody>
</table>

<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>
